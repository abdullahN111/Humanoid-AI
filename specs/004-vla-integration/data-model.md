# Data Model: Vision-Language-Action (VLA) Integration

**Feature**: [spec.md](./spec.md) | **Plan**: [plan.md](./plan.md) | **Date**: 2025-12-30

## Phase 1: Data Model Design

### Overview

This document defines the data models for the Vision-Language-Action (VLA) integration module. The VLA system connects vision processing, natural language understanding, and robotic action execution in a unified framework for humanoid robots. The data models support three main components: voice-to-action processing, cognitive planning with LLMs, and end-to-end autonomous execution.

### Core Data Models

#### 1. VoiceCommand

Represents a voice command received from a user, processed through speech-to-text.

```json
{
  "id": "string (UUID)",
  "timestamp": "ISO 8601 timestamp",
  "rawAudio": "base64 encoded audio data or file reference",
  "transcript": "string (text from speech-to-text)",
  "confidence": "number (0.0-1.0, confidence in transcription)",
  "intent": "CommandIntent object",
  "userId": "string (user identifier)",
  "source": "string (microphone location, user ID, etc.)",
  "language": "string (language code, e.g., 'en-US')",
  "processingTime": "number (milliseconds for STT processing)"
}
```

#### 2. CommandIntent

Represents the interpreted intent from a voice command.

```json
{
  "type": "string (e.g., 'navigation', 'manipulation', 'query', 'action')",
  "action": "string (specific action to perform)",
  "parameters": {
    "target": "string (object, location, or entity)",
    "location": "string (coordinates or named location)",
    "duration": "number (time in seconds)",
    "priority": "string ('low', 'normal', 'high', 'critical')",
    "additional": "object (key-value pairs for additional parameters)"
  },
  "confidence": "number (0.0-1.0, confidence in intent recognition)",
  "entities": "array of Entity objects (recognized named entities)",
  "rawText": "string (original text before intent extraction)"
}
```

#### 3. Entity

Represents a named entity extracted from voice commands.

```json
{
  "type": "string (e.g., 'object', 'location', 'person', 'action')",
  "value": "string (the actual entity value)",
  "confidence": "number (0.0-1.0)",
  "position": {
    "start": "number (start position in text)",
    "end": "number (end position in text)"
  }
}
```

#### 4. ActionPlan

Represents a structured plan generated by the LLM for task execution.

```json
{
  "id": "string (UUID)",
  "taskId": "string (original task identifier)",
  "timestamp": "ISO 8601 timestamp",
  "originalGoal": "string (original natural language goal)",
  "planSteps": "array of PlanStep objects",
  "estimatedDuration": "number (estimated time in seconds)",
  "confidence": "number (0.0-1.0, confidence in plan feasibility)",
  "dependencies": "array of string (other plans this plan depends on)",
  "status": "string ('planning', 'validated', 'executing', 'completed', 'failed')",
  "llmProvider": "string (e.g., 'openai', 'anthropic', 'local')",
  "modelUsed": "string (specific model name)",
  "promptTokens": "number (tokens used in prompt)",
  "completionTokens": "number (tokens in response)"
}
```

#### 5. PlanStep

Represents a single step in an action plan.

```json
{
  "id": "string (UUID)",
  "description": "string (human-readable description)",
  "actionType": "string (e.g., 'navigation', 'manipulation', 'perception', 'wait')",
  "parameters": {
    "target": "string (object, location, or entity)",
    "location": {
      "x": "number (x coordinate)",
      "y": "number (y coordinate)",
      "z": "number (z coordinate)",
      "orientation": {
        "x": "number",
        "y": "number",
        "z": "number",
        "w": "number (quaternion)"
      }
    },
    "object": "string (object name or identifier)",
    "duration": "number (time in seconds)",
    "conditions": "array of Condition objects",
    "timeout": "number (seconds before considering failed)",
    "fallbackAction": "PlanStep object (action to take if this fails)"
  },
  "preconditions": "array of Condition objects",
  "postconditions": "array of Condition objects",
  "dependencies": "array of string (step IDs this step depends on)",
  "priority": "number (execution priority, higher executes first)"
}
```

#### 6. Condition

Represents a condition that must be met for a plan step to execute or be considered complete.

```json
{
  "type": "string (e.g., 'object_detected', 'location_reached', 'grasp_successful', 'timeout')",
  "parameters": {
    "target": "string (object or location)",
    "threshold": "number (confidence or value threshold)",
    "timeout": "number (seconds to wait)",
    "sensor": "string (sensor type or name)"
  },
  "operator": "string ('equals', 'greater_than', 'less_than', 'contains', 'exists')",
  "expectedValue": "any (expected value for the condition)"
}
```

#### 7. ExecutionState

Represents the current state of plan execution.

```json
{
  "planId": "string (ID of the plan being executed)",
  "currentStepId": "string (ID of currently executing step)",
  "completedSteps": "array of string (IDs of completed steps)",
  "failedSteps": "array of string (IDs of failed steps)",
  "executionLog": "array of ExecutionLogEntry objects",
  "robotState": "RobotState object (current state of the robot)",
  "environmentState": "EnvironmentState object (current state of environment)",
  "progress": "number (0.0-1.0, completion percentage)",
  "startTime": "ISO 8601 timestamp",
  "currentTime": "ISO 8601 timestamp",
  "estimatedCompletionTime": "ISO 8601 timestamp"
}
```

#### 8. ExecutionLogEntry

Represents a log entry for plan execution.

```json
{
  "timestamp": "ISO 8601 timestamp",
  "stepId": "string (ID of the step)",
  "status": "string ('started', 'completed', 'failed', 'skipped')",
  "message": "string (status message or error)",
  "duration": "number (execution time in milliseconds)",
  "details": "object (step-specific details)",
  "confidence": "number (0.0-1.0, confidence in execution success)"
}
```

#### 9. RobotState

Represents the current state of the robot.

```json
{
  "position": {
    "x": "number",
    "y": "number",
    "z": "number",
    "orientation": {
      "x": "number",
      "y": "number",
      "z": "number",
      "w": "number (quaternion)"
    }
  },
  "batteryLevel": "number (0.0-1.0)",
  "jointStates": {
    "jointName": "number (position in radians)",
    "...": "..."
  },
  "gripperState": {
    "left": "string ('open', 'closed', 'partially_open')",
    "right": "string ('open', 'closed', 'partially_open')",
    "leftPosition": "number (0.0-1.0)",
    "rightPosition": "number (0.0-1.0)"
  },
  "sensors": {
    "camera": "boolean (is camera active)",
    "lidar": "boolean (is lidar active)",
    "microphone": "boolean (is microphone active)",
    "imu": "boolean (is IMU active)"
  },
  "capabilities": {
    "navigation": "boolean",
    "manipulation": "boolean",
    "perception": "boolean",
    "speech": "boolean"
  }
}
```

#### 10. EnvironmentState

Represents the current state of the environment.

```json
{
  "objects": "array of ObjectState objects",
  "obstacles": "array of Obstacle objects",
  "navigationMap": "string (map identifier or file reference)",
  "lighting": {
    "intensity": "number (0.0-1.0)",
    "colorTemperature": "number (in Kelvin)"
  },
  "acoustics": {
    "noiseLevel": "number (0.0-1.0)",
    "reverberation": "number (0.0-1.0)"
  },
  "timestamp": "ISO 8601 timestamp"
}
```

#### 11. ObjectState

Represents the state of an object in the environment.

```json
{
  "id": "string (object identifier)",
  "name": "string (object name)",
  "type": "string (e.g., 'furniture', 'tool', 'food', 'obstacle')",
  "position": {
    "x": "number",
    "y": "number",
    "z": "number",
    "orientation": {
      "x": "number",
      "y": "number",
      "z": "number",
      "w": "number (quaternion)"
    }
  },
  "dimensions": {
    "width": "number",
    "height": "number",
    "depth": "number"
  },
  "properties": {
    "movable": "boolean",
    "graspable": "boolean",
    "edible": "boolean",
    "fragile": "boolean",
    "material": "string",
    "weight": "number (in kg)"
  },
  "confidence": "number (0.0-1.0, confidence in detection)",
  "lastSeen": "ISO 8601 timestamp"
}
```

#### 12. Obstacle

Represents an obstacle in the environment.

```json
{
  "id": "string (obstacle identifier)",
  "type": "string ('static', 'dynamic', 'temporary')",
  "position": {
    "x": "number",
    "y": "number",
    "z": "number"
  },
  "dimensions": {
    "width": "number",
    "height": "number",
    "depth": "number"
  },
  "traversable": "boolean (whether robot can navigate around/through)",
  "lastUpdated": "ISO 8601 timestamp"
}
```

### API Data Contracts

#### 1. Voice Processing Service

**Request: ProcessVoiceCommand**
```json
{
  "audioData": "base64 encoded audio or file URL",
  "language": "string (default: 'en-US')",
  "userId": "string (optional user identifier)",
  "context": "object (optional context for intent recognition)"
}
```

**Response: ProcessVoiceCommand**
```json
{
  "success": "boolean",
  "commandId": "string (UUID of processed command)",
  "transcript": "string (text from speech-to-text)",
  "intent": "CommandIntent object",
  "confidence": "number (0.0-1.0)",
  "processingTime": "number (milliseconds)",
  "error": "string (error message if success is false)"
}
```

#### 2. Cognitive Planning Service

**Request: GenerateActionPlan**
```json
{
  "goal": "string (natural language goal)",
  "context": {
    "robotCapabilities": "array of string",
    "environmentState": "EnvironmentState object",
    "robotState": "RobotState object",
    "constraints": {
      "timeLimit": "number (seconds)",
      "safetyConstraints": "array of string",
      "resourceLimits": "object"
    }
  },
  "userId": "string (optional user identifier)"
}
```

**Response: GenerateActionPlan**
```json
{
  "success": "boolean",
  "planId": "string (UUID of generated plan)",
  "plan": "ActionPlan object",
  "confidence": "number (0.0-1.0)",
  "processingTime": "number (milliseconds)",
  "error": "string (error message if success is false)"
}
```

#### 3. Plan Execution Service

**Request: ExecutePlan**
```json
{
  "planId": "string (ID of plan to execute)",
  "executionParameters": {
    "speedFactor": "number (0.1-2.0, execution speed multiplier)",
    "safetyLevel": "string ('conservative', 'normal', 'aggressive')",
    "maxRetries": "number (max retries per failed step)"
  }
}
```

**Response: ExecutePlan**
```json
{
  "success": "boolean",
  "executionId": "string (UUID of execution instance)",
  "initialState": "ExecutionState object",
  "error": "string (error message if success is false)"
}
```

### ROS 2 Message Definitions

#### 1. VoiceCommand.msg
```
string id
builtin_interfaces/Time timestamp
string transcript
float32 confidence
CommandIntent intent
string user_id
string source
string language
uint32 processing_time_ms
```

#### 2. CommandIntent.msg
```
string type
string action
KeyValue[] parameters
float32 confidence
Entity[] entities
string raw_text

# KeyValue and Entity would be custom message types
```

#### 3. ActionPlan.msg
```
string id
string task_id
builtin_interfaces/Time timestamp
string original_goal
PlanStep[] plan_steps
float32 estimated_duration
float32 confidence
string[] dependencies
string status
string llm_provider
string model_used
uint32 prompt_tokens
uint32 completion_tokens
```

### Data Flow Patterns

#### 1. Voice-to-Action Flow
```
Microphone → Audio Stream → STT Service → VoiceCommand → Intent Recognition → CommandIntent → ROS 2 Action
```

#### 2. Cognitive Planning Flow
```
Natural Language Goal → LLM Planning → ActionPlan → Plan Validation → Behavior Tree → ROS 2 Execution
```

#### 3. Execution Monitoring Flow
```
Robot Sensors → EnvironmentState → ExecutionState → Plan Monitoring → Feedback Loop → Plan Adaptation
```

### Data Validation Rules

#### 1. VoiceCommand Validation
- `transcript` must be non-empty string with 1-1000 characters
- `confidence` must be between 0.0 and 1.0
- `timestamp` must be within 10 seconds of current time

#### 2. ActionPlan Validation
- `planSteps` array must contain 1-100 steps
- Each step must have a unique ID
- Estimated duration must be positive
- Confidence must be between 0.0 and 1.0

#### 3. RobotState Validation
- Position coordinates must be within environment bounds
- Battery level must be between 0.0 and 1.0
- Joint positions must be within joint limits

### Performance Considerations

#### 1. Data Size Limits
- Audio data: Maximum 30 seconds per command (approximately 2.5MB)
- Plan size: Maximum 100 steps per plan
- State updates: Maximum 10Hz update rate

#### 2. Storage Requirements
- Voice commands: Retain for 24 hours (configurable)
- Execution logs: Retain for 7 days (configurable)
- Plan templates: Retain indefinitely

#### 3. Indexing Strategy
- VoiceCommand: Index by timestamp and user_id
- ActionPlan: Index by status and creation time
- ExecutionState: Index by planId and timestamp